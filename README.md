# RAG S√©n√©gal - Assistant Budg√©taire

Une application de g√©n√©ration augment√©e par r√©cup√©ration (RAG) sp√©cialis√©e dans l'analyse des documents budg√©taires officiels du S√©n√©gal. Cette application permet de poser des questions en langage naturel sur les documents gouvernementaux et d'obtenir des r√©ponses pr√©cises bas√©es sur le contenu officiel.

## üìã Description

Ce syst√®me RAG combine la puissance de Llama 3.2 avec une base de donn√©es vectorielle ChromaDB pour analyser intelligemment les documents budg√©taires du S√©n√©gal. L'application extrait, indexe et permet d'interroger le contenu des rapports PDF officiels via une interface web intuitive.

## ‚ú® Fonctionnalit√©s principales

- **Extraction PDF intelligente** : Traitement automatique des documents PDF avec PyPDF2
- **Indexation vectorielle** : Conversion des documents en embeddings pour recherche s√©mantique
- **Chat intelligent** : Interface conversationnelle avec historique des √©changes
- **Sources tra√ßables** : Affichage des passages exacts utilis√©s pour g√©n√©rer chaque r√©ponse
- **Upload de documents** : Ajout facile de nouveaux documents via l'interface
- **Exemples pr√©-d√©finis** : Questions types pour d√©couvrir les fonctionnalit√©s
- **Persistance des donn√©es** : Sauvegarde automatique de l'index vectoriel

## üõ†Ô∏è Architecture technique

- **Frontend** : Streamlit avec interface de chat moderne
- **Backend RAG** : Moteur personnalis√© avec ChromaDB
- **LLM** : Llama 3.2 (3B) via Ollama
- **Embeddings** : all-MiniLM-L6-v2 (SentenceTransformers)
- **Base vectorielle** : ChromaDB avec persistance locale
- **Traitement PDF** : PyPDF2 pour l'extraction de texte

## üì¶ Installation

### Pr√©requis

1. **Python 3.8+**
2. **Ollama** install√© et configur√©
3. **Mod√®le Llama 3.2** t√©l√©charg√©

### Installation du projet

1. Clonez le d√©p√¥t :
```bash
git clone https://github.com/M-mbaye30/RagApplication.git
cd RagApplication
```

2. Cr√©ez un environnement virtuel :
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

3. Installez les d√©pendances :
```bash
pip install -r requirements.txt
```

### Configuration d'Ollama

1. Installez Ollama : [https://ollama.ai](https://ollama.ai)

2. T√©l√©chargez le mod√®le Llama 3.2 :
```bash
ollama pull llama3.2:3b
```

3. D√©marrez le serveur Ollama :
```bash
ollama serve
```

Le serveur doit tourner sur `http://localhost:11500`

## üöÄ Utilisation

### Lancement de l'application

```bash
streamlit run app.py
```

L'interface sera accessible sur `http://localhost:8501`

### Utilisation de l'interface

1. **Indexation de documents** :
   - Utilisez le sidebar pour uploader vos PDF
   - Cliquez sur "Indexer ce document"
   - Attendez la confirmation d'indexation

2. **Questionnement** :
   - Tapez votre question dans le chat
   - Obtenez une r√©ponse bas√©e sur les documents index√©s
   - Consultez les sources utilis√©es dans l'onglet d√©roulant

3. **Exemples pr√©-d√©finis** :
   - Utilisez les questions d'exemple dans le sidebar
   - Explorez les diff√©rents types de requ√™tes possibles

### Utilisation programmatique

```python
from rag_engine import RAGEngine

# Initialisation
rag = RAGEngine(model_name="llama3.2:3b")

# Indexation d'un document
rag.index_document("rapport_budget_t1_2025.pdf")

# Questionnement
result = rag.generate_answer("Quel est le montant des recettes fiscales ?")
print(result["answer"])
print(f"Sources: {len(result['sources'])}")
```

## üìÅ Structure du projet

```
RagApplication/
‚îÇ
‚îú‚îÄ‚îÄ app.py                    # Interface Streamlit
‚îú‚îÄ‚îÄ rag_engine.py            # Moteur RAG principal
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îú‚îÄ‚îÄ vectorstore/             # Base ChromaDB (cr√©√©e automatiquement)
‚îÇ   ‚îú‚îÄ‚îÄ chroma.sqlite3
‚îÇ   ‚îî‚îÄ‚îÄ documents_senegal/
‚îú‚îÄ‚îÄ documents/               # Dossier pour vos PDF (optionnel)
‚îî‚îÄ‚îÄ README.md               # Ce fichier
```

## ‚öôÔ∏è Configuration avanc√©e

### Param√®tres du RAG

Dans `rag_engine.py`, vous pouvez ajuster :

```python
class RAGEngine:
    def __init__(self, model_name="llama3.2:3b"):
        # Mod√®le d'embedding
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
    def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 100):
        # Taille des chunks et chevauchement
        
    def search_similar_chunks(self, query: str, n_results: int = 5):
        # Nombre de chunks r√©cup√©r√©s
```

### Personnalisation des prompts

Le prompt RAG dans `generate_answer()` peut √™tre modifi√© pour :
- Changer le style de r√©ponse
- Ajouter des contraintes sp√©cifiques
- Modifier la langue de r√©ponse

## üéØ Exemples de questions

### Questions budg√©taires
- "Quel est le montant total des recettes fiscales au premier trimestre 2025 ?"
- "Comment ont √©volu√© les recettes du S√©n√©gal ?"
- "Quels sont les principaux minist√®res mentionn√©s dans le budget ?"

### Questions d'analyse
- "Quelle est la situation budg√©taire actuelle ?"
- "Quelles sont les principales d√©penses publiques ?"
- "Comment se r√©partissent les recettes non fiscales ?"

## üîß D√©pannage

### Erreurs courantes

**Ollama non accessible** :
```bash
# V√©rifiez qu'Ollama tourne
curl http://localhost:11500/api/version

# Red√©marrez si n√©cessaire
ollama serve
```

**Mod√®le manquant** :
```bash
# T√©l√©chargez le mod√®le
ollama pull llama3.2:3b

# V√©rifiez les mod√®les install√©s
ollama list
```

**Erreur de m√©moire** :
- R√©duisez `chunk_size` dans `rag_engine.py`
- Limitez `n_results` dans les recherches
- Utilisez un mod√®le plus petit : `llama3.2:1b`

### Performance

**Am√©liorer la vitesse** :
- Utilisez un SSD pour `vectorstore/`
- Augmentez la RAM disponible
- Optimisez `chunk_size` selon vos documents

**Am√©liorer la qualit√©** :
- Nettoyez vos PDF avant indexation
- Ajustez les param√®tres de chunking
- Exp√©rimentez avec diff√©rents mod√®les d'embedding

## üìä M√©triques

- **Temps d'indexation** : ~30 secondes par PDF de 50 pages
- **Temps de r√©ponse** : 3-8 secondes selon la complexit√©
- **Pr√©cision** : Score de similarit√© affich√© pour chaque source
- **Capacit√©** : Limit√© par l'espace disque et la RAM

## ü§ù Contribution

1. Fork le projet
2. Cr√©ez votre branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout fonctionnalit√©'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

## üìÑ Licence
